{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50f26b19-2a72-4416-af87-5c73005b960c",
   "metadata": {},
   "source": [
    "# Modeling Troubleshooting \n",
    "\n",
    "- baseline_model 이후\n",
    "    - 모델 pipeline 구조 관련 의문점 해소\n",
    "    - 모델 성능(f1-score) 향상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4429785-0eb2-4e55-aaa4-07bea1de5525",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 AttentionPooling 도입 이유 \n",
    "\n",
    "- 문장에서 aspect-relevant 정보를 강조하려고\n",
    "    - AttentionPooling은 문장 전체에서 aspect에 중요한 토큰들에만 집중해 문맥 벡터를 구성함\n",
    "- [CLS]나 평균보다 유의미한 표현을 학습할 수 있어서\n",
    "    - Transformer의 출력은 [batch, seq_len, hidden] \n",
    "    - [CLS] 벡터 : 항상 맨 앞에 있어서 aspect별 정보 반영이 약할 수 있음\n",
    "    - 평균 풀링 : 모든 토큰을 동일하게 취급 -> 중요 단어가 묻힘\n",
    "    - AttentionPooling :\n",
    "        - 각 토큰의 중요도를 학습해서\n",
    "        - 마지막 은닉 상태 hidden_states에서 중요한 토큰에 더 많은 가중치를 주고\n",
    "        - weighted sum을 통해 하나의 벡터를 추출하기 때문에\n",
    "        - aspect와 관련된 감정 신호를 더 잘 반영함\n",
    "- Multi-aspect 상황에서 중요한 단어가 달라질 때 효과적\n",
    "    - ABSA는 한 문장에서 여러 감정이 섞일 수 있기 때문에 단일한 [CLS] 벡터로는 감정 혼합 표현이 불리함\n",
    "    - -> AttentionPooling은 문맥 내에서 동적으로 중요한 단어를 추출 가능 \n",
    "\n",
    "#### hidden states란? \n",
    "\n",
    "- Transformer 모델의 출력 중 하나\n",
    "- 입력 시퀀스의 각 토큰이 문맥 속에서 어떤 의미를 가지는지 벡터로 표현한 값\n",
    "- 문장의 각 단어가 주변 단어들과 상호작용한 결과로 만들어진 토큰별 임베딩 벡터들\n",
    "- hidden_states.shape = [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "#### hidden states가 필요한 이유 \n",
    "\n",
    "- ABSA - 보통 문장 전체 표현이 필요한 ACD, ASC에 이 벡터를 활용\n",
    "- Attention Pooling - 문장 전체에서 중요한 토큰에 주목하여 의미 벡터 생성\n",
    "- [CLS] Pooling - 첫 번째 토큰(보통 문장 전체 요약 역할)의 벡터만 사용\n",
    "- Mean Pooling - 모든 토큰의 평균을 문장 표현으로 사용\n",
    "- Token-level task - 각 토큰별 분류\n",
    "- Sentence-level task - 문장 전체 감정 분석\n",
    "\n",
    "#### pooled outputd이란? \n",
    "\n",
    "- 문장 전체를 하나의 벡터로 요약한 표현\n",
    "- 보통 Transformer 모델에서 [CLS] 토큰의 hidden state를 가공해서 만든 문장 레벨 표현\n",
    "\n",
    "#### Electra에 pooled_out이 없는 이유 \n",
    "\n",
    "- Electra는 BertModel과 구조가 비슷하지만 차이가 있음\n",
    "    - Electra의 AutoModel은 outputs.last_hidden_state만 제공하고, BERT처럼 [CLS] 위치를 따로 분리한 pooled_output이 없음\n",
    "        - 방법1 : [CLS]를 쓰려면 last_hidden_state[:, 0, :] 사용\n",
    "        - 방법2 : AttentionPooling 사용\n",
    " \n",
    "#### 우리 모델에서 AttentionPooling의 역할 \n",
    "\n",
    "- 단순히 형식 맞추기가 아니라 실제로 유의미한 attention 기반의 가중합(pooling)을 수행하는 역할\n",
    "- 단순히 [CLS] 토큰만 쓰는 대신 입력 시퀀스 전체에서 중요한 토큰에 가중치를 부여해서 문장 표현을 만들려고 한 것\n",
    "\n",
    "#### AttentionPooling의 실제 작동 방식 \n",
    "\n",
    "- 각 토큰에 대해 중요도를 학습된 방식으로 스코어링하고,\n",
    "- attention_mask를 이용해 패딩 토큰은 제외하고,\n",
    "- 가중치를 곱해 전체 시퀀스의 가중 평균을 계산함\n",
    "- -> 단순 평균이나 [CLS]보다는 더 똑똑한 문장 요약을 만들 수 있다는 장점이 있음\n",
    "\n",
    "#### AttetionPooling의 장점 \n",
    "\n",
    "- 단순 평균이나 [CLS]보다 더 정보에 민감한 표현 가능\n",
    "- 문장에서 중요한 토큰에 더 큰 가중치를 부여해서 성능 향상 기대"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0496ad88-8ac9-405d-bc6d-c0ec678502fb",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 GradScaler 도입 이유 \n",
    "\n",
    "- 훈련 속도 향상\n",
    "    - float16으로 연산하면 GPU에서 속도가 훨씬 빨라지고 VRAM도 덜 사용함 \n",
    "    - -> 더 큰 배치 처리 가능\n",
    "- 스케일링 & Underflow 방지\n",
    "    - float16은 표현 가능한 숫자가 작아서 작은 gradient 값이 0으로 사라지는 현상(underflow) 발생\n",
    "    - -> GradScaler가 자동으로 loss 값을 키워서 문제 방지\n",
    "\n",
    "#### GradScaler란? \n",
    "\n",
    "- Mixed Precision Training (혼합 정밀도 학습)을 할 때 수치적으로 안정적인 학습을 가능하게 해주는 도구\n",
    "- PyTorch에서 torch.cuda.amp.GradScaler로 제공됨\n",
    "- 주로 autocast()와 함께 사용됨\n",
    "\n",
    "#### autocast()란? \n",
    "\n",
    "- PyTorch에서 제공하는 자동 혼합 정밀도(Auto Mixed Precision) 기능\n",
    "- float32 대신 일부 연산을 자동으로 float16으로 변환해 실행하는 컨텍스트 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f98f48-74b1-43e6-a263-e8e6ae844f28",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 layer_norm 위치 \n",
    "\n",
    "| 구조              | 사용 예               | 장점                                 |\n",
    "|-------------------|------------------------|--------------------------------------|\n",
    "| **Post-LN** Linear → Act → LN | BERT, RoBERTa 등       | 직관적 구조, shallow network에 안정 |\n",
    "| **Pre-LN** LN → Linear → Act  | GPT-2, GPT-J, T5 등    | deep network에서 gradient 안정성 ↑<br>학습 초기 단계에서 성능 유지에 유리 |\n",
    "\n",
    "- ABSA는 비교적 shallow architecture로 구성되어 있어서 Post-LN으로도 충분히 안정적이며 성능도 잘 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d6fd94-2b1f-4e61-8c6b-63c4f17ca792",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 LayerNorm vs BatchNorm vs NoNorm \n",
    "\n",
    "- BERT 계열에서는 LayerNorm이 기본 (배치에 의존하지 않고 안정적)\n",
    "- BatchNorm은 일반적으로 CNN 기반에서 사용됨\n",
    "- Transformer에선 LayerNorm을 써야 안정적임 (BatchNorm은 피하는 게 좋음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f69e6-2969-4019-9a2f-23a2956299a4",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 annotation 없을 법한 문장 제거 후 predict \n",
    "\n",
    "- 평가 성능(F1 score)은 좋아질 수 있지만, 실제 의미 있는 성능 개선을 아닐 수 있음\n",
    "- 데이터 분포의 왜곡\n",
    "    - 원래 데이터에는 ‘속성 없음’ 문장이 일정 비율 포함되어 있음\n",
    "    - 이를 제거하면 모델은 속성이 항상 존재하는 상황만 예측하게 되어 실제 사용 환경에서의 일반화 성능이 떨어질 수 있음\n",
    "- 성능 과대 평가\n",
    "    - 속성 없는 문장은 예측이 어려워 성능을 떨어뜨릴 수 있음\n",
    "    - 이를 제거하면 결과적으로 쉬운 데이터만 predict 하게 되어 F1 score가 부풀려질 수 있음\n",
    "\n",
    "#### 대안 : no aspect('없음') 클래스를 훈련시키지 않고 threshold로 처리\n",
    "\n",
    "- 모델 설계 단순화\n",
    "    - '없음'이라는 별도 클래스를 추가하지 않아도 됨 -> 클래스 수 고정\n",
    "- 직관적인 제어 가능\n",
    "    - threshold를 조절하여 예측 민감도를 직접 컨트롤 가능\n",
    "- 노이즈 제거 가능\n",
    "    - 불확실한 예측을 '없음'으로 버림으로써 precision 향상 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768602e-a261-4ca7-88b5-3a6338ee1fcc",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 threshold 설정 (last model 기준)\n",
    "\n",
    "- ACD\n",
    "    - min: 0.7700, mean: 0.9999, median: 1.0000\n",
    "    - 거의 모든 예측의 confidence가 0.99 ~ 1.0 근처\n",
    "- ASC\n",
    "    - min: 0.5777, mean: 0.9967, median: 1.0000\n",
    "    - 대부분의 예측 confidence가 매우 높지만, 간혹 0.6대인 예측도 있음\n",
    "\n",
    "#### 결론 \n",
    "\n",
    "- 대부분의 예측이 매우 confident하다\n",
    "    - 거의 모든 예측이 softmax 확률 0.99 ~ 1.0\n",
    "    - 모델이 거의 확신에 가까운 판단만 하고 있음\n",
    "- threshold의 영향이 없을 가능성\n",
    "    - 이미 대부분 예측이 매우 confident 하기 때문에 threshold가 filtering에 큰 영향을 끼치지 않을 수 있음\n",
    "    - 따라서 threshold를 보수적으로 0.9 이상으로 설정\n",
    "    - -> 낮은 confidence 예측만 제한적으로 filtering 하는 것이 적절하다고 판단 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a96d0b-24c5-4232-87cd-72908b8ac769",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 f1-score 계산 방식 (전체 vs 속성별)\n",
    "\n",
    "| 항목               | evaluation_f1                                     | evaluation_per_aspect                        |\n",
    "|--------------------|-----------------------------------------------------|------------------------------------------------|\n",
    "| 평가 단위      | 전체 set 비교 (속성 또는 속성+감성 쌍)           | 각 aspect에 대한 binary 분류                   |\n",
    "| 감성 포함 여부 | 포함 ((aspect, polarity) 쌍 기준 평가 가능)       | 미포함 (aspect 존재 여부만 평가)              |\n",
    "| 정답 조건      | 완전 일치 (예측이 정답과 동일해야 TP로 인정됨)     | 해당 aspect 포함 여부만 확인                  |\n",
    "| 계산 방식      | TP/FP/FN 직접 계산 후 수식으로 Precision/Recall/F1 | sklearn의 f1_score() 등 내장 함수 사용    |\n",
    "| 출력 형태      | 전체 모델 성능 요약 (category + pipeline 2종류)    | 각 속성별 Precision / Recall / F1 / Support   |\n",
    "| 사용 목적      | 모델 전반 성능 평가 (논문/대회 평가 기준)          | 세부 속성별 성능 분석 (어디서 약한지 확인)     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62869a4e-6f0d-45db-8bbc-15ff79e31778",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 lable_smoothing 적용 \n",
    "\n",
    "- 추가 클래스를 따로 정의할 필요 없이\n",
    "- PyTorch 1.10 이후부터는 nn.CrossEntropyLoss에서 label_smoothing 인자를 공식적으로 지원함\n",
    "\n",
    "#### lable_smoothing 이란? \n",
    "\n",
    "- 딥러닝 분류 문제에서 모델의 과신(overconfidence)을 줄이기 위한 정규화 기법\n",
    "- 잘못된 예측에 대해 로스 급증을 완화함\n",
    "- 노이즈가 있는 라벨에 대해 더 유연하게 학습함\n",
    "- 테스트셋에서 성능 향상될 수 있음 (특히 불균형 클래스일 때 유효)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779df05-0fdb-4669-86cc-9b348d9d4a37",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 활성화 함수 교체 \n",
    "\n",
    "- GELU (Gaussian Error Linear Unit)\n",
    "    - Tanh보다 부드러운 활성화 함수\n",
    "    - BERT, RoBERTa, ELECTRA 등 많은 사전 학습 모델에서 기본으로 사용\n",
    "    - 수식은 x * P(X ≤ x) 형태로 확률 분포 기반의 곡선 형태\n",
    "\n",
    "#### 결과 : 성능 하락 \n",
    "\n",
    "- ReLU는 일정 이하의 값을 0으로 날려 버려서 정제 역할을 해주는데, GELU는 그걸 안 해줘서 복잡도가 높아짐\n",
    "- 음수 영역의 값도 일부 통과시켜서 모델이 더 많은 feature를 살리는 경향이 있음\n",
    "- 데이터셋이 작거나 noisy한 feature가 많은 경우, 오히려 과적합으로 이어질 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c991dd-fd7c-40ca-ac29-38ae6812ea44",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 Multi Dropout (stochastic dropout) 도입 \n",
    "\n",
    "- 각 dropout이 랜덤하게 노드를 drop함 \n",
    "- 여러 개의 dropout을 통과시켜서 평균을 취함 -> stochastic regularization 효과\n",
    "- 일반적으로 ensemble과 비슷한 효과\n",
    "\n",
    "#### 결과 : 성능 하락 \n",
    "\n",
    "- MultiDropout은 일반적으로 대규모 데이터에서 성능 향상을 보여줌\n",
    "- 데이터가 적거나 noise가 많은 경우에는 오히려 학습을 방해하는 요소가 될 수 있음\n",
    "\n",
    "#### 뒤늦게 든 생각 \n",
    "\n",
    "- Multi Dropout 도입 후 추론 시에도 model.train() 상태 유지가 필요한데\n",
    "- 실수로 model.eval()에서 예측함 -> 그냥 평균이 의미 없는 예측이 됨\n",
    "- 실제로 MultiDropout이 작동을 안 했던 듯 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763daf83-fa3e-40e5-abea-01c040c7753b",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 데이터 증강 기법 \n",
    "\n",
    "| 기법 | 설명 | 장점 | 단점 |\n",
    "|------|------|------|------|\n",
    "| Back Translation (역번역) | 문장을 외국어로 번역 후 다시 원어로 번역 | - 문장 구조 다양화<br>- 의미 보존 잘 됨 | - 속성 단어 누락 위험<br>- 감정 왜곡 가능성 |\n",
    "| Synonym Replacement (유의어 치환) | 감정 표현이나 속성을 유의어로 교체 | - 간단하고 빠름<br>- 레이블 유지 쉬움 | - 표현 다양성 부족<br>- 맥락 무시 가능성 |\n",
    "| Template-based Generation | 템플릿에 속성과 감정을 끼워넣어 문장 생성 | - 레이블 정확도 높음<br>- 통제 가능 | - 문장 어색할 수 있음<br>- 다양성 낮음 |\n",
    "| Conditional Generation | “속성=향, 감정=긍정” → LLM이 문장 생성 | - 표현 다양성 높음<br>- 유연한 활용 | - 제어 어려움<br>- 라벨 오류 가능성 |\n",
    "| Random Insertion/Deletion | 감정 수식어를 임의로 삽입 또는 삭제 | - 간단<br>- 문장 자연도 유지 가능 | - 감정 세기 왜곡<br>- 의미 손상 가능 |\n",
    "| MixUp / Interpolation | 둘 이상의 문장을 섞거나 연결 | - 과적합 방지<br>- 학습 일반화 유도 | - 문장 비자연적<br>- 감정/속성 모호성 |\n",
    "| Entity Swap (속성 교체) | 동일 감정 문장에서 속성만 변경 | - 속성 다양화<br>- 감정-속성 분리 가능 | - 문맥 불일치 가능<br>- 레이블 검증 필요 |\n",
    "| Paraphrasing | 문장 의미 유지하면서 표현만 바꿈 | - 다양성 증가<br>- 문장 자연스러움 | - LLM 필요<br>- 속성/감정 왜곡 가능성 |\n",
    "| Weakly Supervised Labeling | 라벨 없는 문장에 약한 모델로 자동 라벨링 | - 데이터 확장에 유리 | - 라벨 정확도 낮음<br>- 학습 품질 저하 가능 |\n",
    "| Style Transfer | 감정 스타일을 긍정↔부정으로 변경 | - 감정 다양화<br>- 실험적 활용 가능 | - 감정 오류 가능<br>- ABSA에선 라벨 위험성 ↑ |\n",
    "\n",
    "#### Back Translation (역번역) 채택 \n",
    "\n",
    "- 문장 구조를 다양화하면서 의미(속성·감정)을 유지할 수 있기 때문\n",
    "    - 모델이 같은 의미의 다양한 표현을 학습 가능\n",
    "- 노이즈가 적고 자동화하기 쉬운 증강 방식\n",
    "    - 직접 문장을 쓰거나 템플릿을 설계하지 않아도 됨\n",
    "    - 번역기만 있으면 대규모 자동 생성 가능\n",
    "    - 감정 극성만 바뀌지 않게 하면 라벨 유지가 쉬움\n",
    "- 감정 표현의 범위 확장에 효과적\n",
    "    - 모델이 감정 표현에 과적합되지 않고 일반화된 감정 인식을 학습할 수 있음\n",
    "- ABSA의 두 단계(ACD + ASC)에 모두 효과 있음\n",
    "    - ACD (속성 인식) : 다양한 표현에서도 속성 감지 가능\n",
    "    - ASC (감정 분류) : 같은 감정을 다양한 문장으로 표현해도 감정 극성 학습 가능\n",
    "\n",
    "#### 중립/부정 감정 리뷰만 증강 \n",
    "\n",
    "- 데이터 불균형 완화\n",
    "- 모델이 부정/중립 감정을 잘 못 잡을 때가 많음\n",
    "    - 부정 표현은 다양하고 은근함 (ex. \"별로다\", \"추천은 안 해요\", \"기대보단 그저 그랬어요\")\n",
    "    - 중립 표현은 긍정/부정 중간이라 경계 모호 (ex. \"괜찮았어요\", \"보통이에요\", \"그럭저럭\")\n",
    "    - -> 중립/부정을 증강하면 판단 기준이 더 명확해지고, 성능 개선됨\n",
    "- F1 score 향상에 직결\n",
    "    - 감정 분류는 보통 macro F1을 사용\n",
    "    - 이는 모든 클래스의 F1을 평균하기 때문에 소수 클래스(중립/부정) 성능이 떨어지면 overall F1이 낮아짐\n",
    "    - -> 중립/부정을 증강하면 전체 성능이 개선\n",
    "- 데이터 증강이 긍정에선 오히려 역효과일 수 있음\n",
    "    - 긍정 리뷰는 이미 많고 다양하므로 역번역으로 증강하면 중복·의미 훼손 위험 커짐 -> 모델에 noise 더하게 됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb0eb2-f1f6-42f8-854c-b6c71f4bc79f",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 StratifiedKFold 도입 \n",
    "\n",
    "- 불균형한 데이터 분포 대응\n",
    "    - 긍정 90%, 부정 10% 같은 데이터일 경우, 일반 KFold는 어떤 fold에 부정이 거의 없을 수 있음 -> 성능 왜곡\n",
    "- 신뢰성 있는 평가\n",
    "    - 각 fold의 클래스 분포가 비슷하므로 검증 성능이 더 일관되고 신뢰 가능함\n",
    "- ABSA의 감정 분류(ASC)에서 특히 중요\n",
    "    - 감정 클래스(positive/neutral/negative)의 분포가 한쪽으로 쏠려 있으면,\n",
    "    - 모델이 긍정만 예측해도 높게 평가될 수 있음\n",
    "- 증강 데이터 포함 시에도 클래스 균형 보장\n",
    "\n",
    "#### StratifiedKFold란? \n",
    "\n",
    "- 분류 문제에서 클래스(레이블) 분포를 유지한 채 데이터를 K개로 나누는 교차 검증 방법\n",
    "- 훈련/검증 데이터로 나눌 때 각 클래스(예: 긍정/부정/중립)의 비율이 원래 데이터와 비슷하게 유지되도록 분할함\n",
    "- shuffle=True -> 데이터를 무작위로 섞고 나서 Fold를 나눔\n",
    "- 하지만 random_state=1이 고정 -> 항상 같은 방식으로 섞여서 같은 Fold 순서가 보장됨\n",
    "    - random_state는 StratifiedKFold 안에서만 작동함\n",
    "\n",
    "#### set_seed(1, device) \n",
    "\n",
    "- 목적 : 폴드 분할의 순서를 항상 동일하게 유지하기 위해서\n",
    "- 데이터 로딩 순서에 무작위성 있을 경우 무작위성 제어\n",
    "- 모델 학습에서 재현성 유지\n",
    "- 이후 다른 무작위 연산 대비\n",
    "- -> set_seed()는 K-Fold 분할이 아닌 전체 실험 흐름의 무작위성 제어를 위한 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd248e-3a6f-44bc-b907-63ac00374656",
   "metadata": {},
   "source": [
    "--- \n",
    "### 📍 Spacing 도입 \n",
    "\n",
    "#### 결과 : 성능 상승 \n",
    "\n",
    "- Tokenizer가 올바르게 토큰 분리 가능\n",
    "- Aspect 단어 인식이 쉬워짐\n",
    "- Pretrained 모델 학습 환경과 맞춰짐\n",
    "    - 많은 사전학습 언어모델들은 띄어쓰기 잘 된 데이터로 학습되어 있음\n",
    "    - ex. 한국어 ELECTRA, KLUE-BERT 등은 뉴스, 위키 기반 데이터 사용\n",
    "    - -> 입력 문장의 띄어쓰기가 잘 되어 있으면 사전학습된 언어모델의 표현력 활용이 극대화됨\n",
    "- 감정 표현 단어가 더 뚜렷해짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298e30b-d318-4b6b-a5ad-290508c2c242",
   "metadata": {},
   "source": [
    "---\n",
    "### 📍 max_len 조정 \n",
    "\n",
    "- 3분위수(Q3) ≈ 95 -> 전체 문장 길이의 75%는 토큰 수가 95 이하\n",
    "    - 모델 입력 토큰의 길이 분포(예: input_ids의 길이) 기준\n",
    "\n",
    "#### max_len = 128 \n",
    "\n",
    "- 충분한 커버리지 확보\n",
    "    - Q3 = 95면 max_len=128은 대부분의 문장을 자르지 않고 처리 가능\n",
    "    - 상위 25% 긴 문장 중 일부를 약간 잘라도 큰 정보 손실 없이 학습 가능\n",
    "- Padding 낭비 최소화\n",
    "- 모델 안정성 유지\n",
    "    - 학습 중 너무 긴 입력은 메모리 문제, gradient exploding 위험 발생 가능\n",
    "    - 128은 일반적으로 BERT 기반 모델에서 안정적인 길이로 간주됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec50685-60e8-49c2-86a2-2bf0a070d2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72acda1-a062-4b6b-bf85-98b233caa0c5",
   "metadata": {},
   "source": [
    "--- \n",
    "### sql db 구축 \n",
    "\n",
    "- load_data.py 생성\n",
    "- db.csv 생성\n",
    "- (bash) python load_data.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32b90-7c3a-4aeb-ac82-e40fabd36867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
